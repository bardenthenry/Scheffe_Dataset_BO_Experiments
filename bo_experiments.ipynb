{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/appuser/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms import Standardize\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition import ExpectedImprovement, LogExpectedImprovement, PosteriorMean, UpperConfidenceBound\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "from pprint import pprint\n",
    "from typing import Optional\n",
    "from src.scheffe_generator import ScheffeGenerator\n",
    "\n",
    "# 設定設備與型別\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_single_task_gp(train_x:torch.Tensor, train_y:torch.Tensor, kernel_type:str='RBF') -> SingleTaskGP:\n",
    "    '''\n",
    "    This function sets up a SingleTaskGP surrogate model with the specified kernel type (RBF or Matern).\n",
    "    Parameters:\n",
    "    train_x: Training input data as a torch.Tensor.\n",
    "    train_y: Training output data as a torch.Tensor.\n",
    "    kernel_type: The type of kernel to use for the GP model ('RBF' or 'Matern').\n",
    "    Returns:\n",
    "    surrogate_model: The configured SingleTaskGP model.\n",
    "    '''\n",
    "    if kernel_type == 'RBF':\n",
    "        surrogate_model = SingleTaskGP(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            outcome_transform=Standardize(m=train_y.shape[-1])\n",
    "        )\n",
    "    elif kernel_type == 'Matern':\n",
    "        covar_module = ScaleKernel(\n",
    "            MaternKernel(nu=2.5)\n",
    "        )\n",
    "        surrogate_model = SingleTaskGP(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            covar_module=covar_module,\n",
    "            outcome_transform=Standardize(m=train_y.shape[-1])\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError('Unsupported kernel type, kernel_type should be \"RBF\" or \"Matern\".')\n",
    "\n",
    "    return surrogate_model\n",
    "\n",
    "def one_bo_step_with_gp_ei(\n",
    "    train_x:torch.Tensor,\n",
    "    train_y:torch.Tensor,\n",
    "    kernel_type:str,\n",
    "    best_f:torch.Tensor,\n",
    "    bounds:torch.Tensor,\n",
    "    constraints=None,\n",
    "    acquisition_type:str='LogEI'\n",
    ") -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, SingleTaskGP]:\n",
    "    '''\n",
    "    This function performs one step of Bayesian Optimization using a Gaussian Process surrogate model and an acquisition function (LogEI or UCB).\n",
    "    The output of this function is:\n",
    "    candidate: The next evaluation point suggested by the acquisition function.\n",
    "    acq_value: The acquisition function value at the candidate point.\n",
    "    best_predicted_x: The point that the surrogate model predicts to be the best.\n",
    "    surrogate_model: The trained surrogate model (Gaussian Process).\n",
    "    '''\n",
    "    # build surrogate model with GP\n",
    "    surrogate_model = set_single_task_gp(train_x, train_y, kernel_type=kernel_type)\n",
    "\n",
    "    # Find Surrogate Model Best Point\n",
    "    post_mean_func = PosteriorMean(model=surrogate_model)\n",
    "    if constraints is not None:\n",
    "        best_predicted_x, _ = optimize_acqf(\n",
    "            acq_function=post_mean_func,\n",
    "            bounds=bounds,\n",
    "            q=1,\n",
    "            num_restarts=20,\n",
    "            raw_samples=256,\n",
    "            equality_constraints=constraints,\n",
    "        )\n",
    "    else:\n",
    "        best_predicted_x, _ = optimize_acqf(\n",
    "            acq_function=post_mean_func,\n",
    "            bounds=bounds,\n",
    "            q=1,\n",
    "            num_restarts=20,\n",
    "            raw_samples=256\n",
    "        )\n",
    "\n",
    "    mll = ExactMarginalLogLikelihood(surrogate_model.likelihood, surrogate_model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # 定義獲取函數\n",
    "    if acquisition_type == 'LogEI':\n",
    "        acqu_fun = LogExpectedImprovement(model=surrogate_model, best_f=best_f)\n",
    "    elif acquisition_type == 'UCB':\n",
    "        acqu_fun = UpperConfidenceBound(model=surrogate_model)\n",
    "    else:\n",
    "        raise ValueError('Unsupported acquisition type, the acquisition_type should be \"LogEI\" or \"UCB\".')\n",
    "    \n",
    "    # 最適化獲取函數以找到下一個評估點\n",
    "    if constraints is not None:\n",
    "        candidate, acq_value = optimize_acqf(\n",
    "            acq_function=acqu_fun,\n",
    "            bounds=bounds,\n",
    "            q=1,\n",
    "            num_restarts=20,\n",
    "            raw_samples=256,\n",
    "            equality_constraints=constraints,\n",
    "        )\n",
    "    else:\n",
    "        candidate, acq_value = optimize_acqf(\n",
    "            acq_function=acqu_fun,\n",
    "            bounds=bounds,\n",
    "            q=1,\n",
    "            num_restarts=20,\n",
    "            raw_samples=256,\n",
    "        )\n",
    "    \n",
    "    return candidate, acq_value, best_predicted_x, surrogate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_loop(\n",
    "    train_x:torch.Tensor,\n",
    "    train_obj:torch.Tensor,\n",
    "    gt_x:torch.Tensor,\n",
    "    gt_y:float,\n",
    "    gt_func,\n",
    "    bounds:torch.Tensor,\n",
    "    constraints:Optional[list]=None,\n",
    "    n_iterations:int=20,\n",
    "    kernel_type:str='RBF',\n",
    "    acquisition_type:str='LogEI',\n",
    "    gt_func_noiseless: bool = False\n",
    "):\n",
    "    '''\n",
    "    This function performs the Bayesian Optimization loop for a specified number of iterations.\n",
    "    Parameters:\n",
    "    train_x: Initial training input data as a torch.Tensor.\n",
    "    train_obj: Initial training output data as a torch.Tensor.\n",
    "    gt_x: Ground truth optimal input data as a torch.Tensor.\n",
    "    gt_y: Ground truth optimal output value as a float.\n",
    "    gt_func: The oracle function to evaluate.\n",
    "    bounds: The bounds for the input space as a torch.Tensor.\n",
    "    constraints: Optional list of constraints for the optimization.\n",
    "    n_iterations: Number of BO iterations to perform.\n",
    "    kernel_type: The type of kernel to use for the GP model ('RBF' or 'Matern').\n",
    "    acquisition_type: The type of acquisition function to use ('LogEI' or 'UCB').\n",
    "    '''\n",
    "    best_f = train_obj.max()\n",
    "\n",
    "    inference_regrets = [] # 用來存 inference regret 的數值\n",
    "    simple_regrets = [] # 用來儲存 simple regret 的數值\n",
    "\n",
    "    for iteration in range(n_iterations):\n",
    "        candidate, acq_value, best_predicted_x, surrogate_model = one_bo_step_with_gp_ei(\n",
    "            train_x, train_obj, kernel_type, best_f, bounds, constraints, acquisition_type\n",
    "        )\n",
    "\n",
    "        # Evaluate the oracle function at the candidate point\n",
    "        \n",
    "        new_y = gt_func( X=candidate.cpu().numpy(), noiseless=gt_func_noiseless)\n",
    "        new_y = torch.tensor(new_y, device=device).unsqueeze(0)\n",
    "\n",
    "        # Update training data\n",
    "        train_x = torch.cat([train_x, candidate], dim=0)\n",
    "        train_obj = torch.cat([train_obj, new_y], dim=0)\n",
    "\n",
    "        # Update best observed value\n",
    "        if new_y > best_f:\n",
    "            best_f = new_y\n",
    "\n",
    "        # Calculate regrets\n",
    "        inferred_y = gt_func(best_predicted_x.cpu().numpy(), noiseless=gt_func_noiseless)\n",
    "        inference_regret = float(gt_y - inferred_y[0])\n",
    "        simple_regret = float(gt_y - best_f.cpu().item())\n",
    "        inference_regrets.append(inference_regret)\n",
    "        simple_regrets.append(simple_regret)\n",
    "        print(f'Iter {iteration+1}/{n_iterations}' + '-'*50)\n",
    "        print(f'Ground True: {gt_y:.3f} New Value: {new_y.item():.3f}, Best Value: {best_f.item():.3f}')\n",
    "        print(f'Ground True X: {np.array2string(gt_x.cpu().numpy(), precision=3, suppress_small=True)}')\n",
    "        print(f'New Candidate: {np.array2string(candidate.cpu().numpy(), precision=3, suppress_small=True)}')\n",
    "\n",
    "    return train_x, train_obj, surrogate_model, inference_regrets, simple_regrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Number of Optimization Step\n",
    "n_interations = 20\n",
    "ninit = 10\n",
    "dataset_path = '/workspaces/BO_EXPERIMENTS/src/datasets/D=10_N=1_K=5/oracle_data_D10_A_000.pt'\n",
    "dataset = torch.load(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_star', 'f_star', 'generator_seed'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['ground_truth'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dataset['initial_data']['X'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[:ninit, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set Oracle Function\n",
    "D = dataset['config']['D']\n",
    "variant = dataset['config']['variant']\n",
    "k_active = dataset['config']['k_active']\n",
    "seed = dataset['config']['seed']\n",
    "gen = ScheffeGenerator( D=D, k_active=k_active, variant=variant, seed=seed )\n",
    "gt_func = gen.oracle\n",
    "\n",
    "# initial dataset\n",
    "train_x = dataset['initial_data']['X'].to(device)\n",
    "train_obj = dataset['initial_data']['Y'].to(device)\n",
    "gt_x = dataset['ground_truth']['x_star'].to(device)\n",
    "gt_y = dataset['ground_truth']['f_star']\n",
    "\n",
    "# Set X bound\n",
    "bounds = torch.stack([torch.zeros(D), torch.ones(D)]).to(device, dtype=dtype)\n",
    "\n",
    "# Set constraints\n",
    "constraints = [\n",
    "    (\n",
    "        torch.arange(D, device=device), # indices: X 的哪些維度要參與計算\n",
    "        torch.ones(D, dtype=dtype, device=device), # coefficients: 這些維度的係數\n",
    "        1.0 # rhs: 等號右邊的值 (Sum = 1.0)\n",
    "    )\n",
    "]\n",
    "\n",
    "# Run Optimization Loop\n",
    "final_train_x, final_train_obj, final_surrogate_model, inference_regrets, simple_regrets = optimization_loop(\n",
    "    train_x=train_x,\n",
    "    train_obj=train_obj,\n",
    "    gt_x=gt_x,\n",
    "    gt_y=gt_y,  \n",
    "    gt_func=gt_func,\n",
    "    bounds=bounds,\n",
    "    constraints=constraints,\n",
    "    n_iterations=n_interations,\n",
    "    kernel_type='RBF',\n",
    "    acquisition_type='LogEI',\n",
    "    gt_func_noiseless=True\n",
    ")\n",
    "\n",
    "# 出現以下 warning 代表優化器在滿足 等式約束 (Equality Constraints) 的超平面上移動時，遇到了嚴重的數值梯度不穩定。\n",
    "# /home/appuser/.local/lib/python3.12/site-packages/botorch/optim/optimize.py:789: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
    "#[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 8 and message Positive directional derivative for linesearch.')]\n",
    "#Trying again with a new set of initial conditions.\n",
    "#  return _optimize_acqf_batch(opt_inputs=opt_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_regrets = [] # 用來存 inference regret 的數值\n",
    "# simple_regrets = [] # 用來儲存 simple regret 的數值\n",
    "\n",
    "# for i in range(5):\n",
    "#     # Fit GP surrogate model\n",
    "#     gp = SingleTaskGP(train_x, train_obj)\n",
    "#     mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "#     fit_gpytorch_mll(mll)\n",
    "\n",
    "#     # Find Surrogate Model Best Point\n",
    "#     post_mean_func = PosteriorMean(model=gp)\n",
    "#     best_predicted_x, _ = optimize_acqf(\n",
    "#         acq_function=post_mean_func,\n",
    "#         bounds=bounds,\n",
    "#         q=1,\n",
    "#         num_restarts=10,\n",
    "#         raw_samples=100,\n",
    "#         equality_constraints=constraints,\n",
    "#     )\n",
    "\n",
    "#     # Get New Observe Data\n",
    "#     new_y = gt_func( X=best_predicted_x.cpu().numpy(), noiseless=True)\n",
    "\n",
    "#     # Set Acquisition Function\n",
    "#     best_f = train_obj.max().item()\n",
    "#     EI = LogExpectedImprovement(model=gp, best_f=best_f)\n",
    "\n",
    "#     # Optimize\n",
    "#     candidate, acq_value = optimize_acqf(\n",
    "#         acq_function=EI,\n",
    "#         bounds=bounds,\n",
    "#         q=1,                     # 每次推薦 1 個點\n",
    "#         num_restarts=10,         # 隨機重啟次數（類似 SLSQP 的重啟）\n",
    "#         raw_samples=100,         # 初始採樣點數量\n",
    "#         equality_constraints=constraints,\n",
    "#     )\n",
    "\n",
    "#     # Combine Old and New Observe Data\n",
    "#     train_x = torch.cat([train_x, candidate])\n",
    "#     train_obj = torch.cat([train_obj, torch.tensor(new_y, device=device).unsqueeze(0) ])\n",
    "    \n",
    "#     # Compute Simple Regret\n",
    "#     max_train_obj = train_obj.max().item()\n",
    "#     simple_regret = gt_y - max_train_obj\n",
    "#     simple_regrets.append(simple_regret)\n",
    "\n",
    "#     # Compute Inference Regrets\n",
    "#     infer_regret = float((gt_y - new_y)[0])\n",
    "#     inference_regrets.append(infer_regret)\n",
    "    \n",
    "#     print(f'Epoch {i+1}: Real Best Value: {gt_y:.2f}, Max Train Obj = {max_train_obj:.2f}, Current Train Obj = {float(new_y[0]):.2f}, Simple Regret = {simple_regret:.2f}, Infer Regret = {infer_regret:.2f}, SumX = {candidate.sum().item():.1f}')\n",
    "\n",
    "# output = {\n",
    "#     'inference_regrets': inference_regrets,\n",
    "#     'simple_regrets': simple_regrets,\n",
    "#     'opt_x': candidate.cpu().numpy().tolist(),\n",
    "#     'opt_y': float(new_y[0])\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in gp.named_parameters():\n",
    "#     print(f\"參數名: {name} | 數值: {param.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 測試預測點\n",
    "# test_tensor = torch.tensor([[100,100,100]], dtype=torch.double).to(device)\n",
    "# with torch.no_grad():\n",
    "#     # 取得後驗分佈\n",
    "#     posterior = gp.posterior(test_tensor)\n",
    "    \n",
    "#     # 取得預測平均值 (Mean)\n",
    "#     mean = posterior.mean\n",
    "    \n",
    "#     # 取得預測變異數 (Variance) 或 標準差 (Stddev)\n",
    "#     variance = posterior.variance\n",
    "#     stddev = torch.sqrt(variance)\n",
    "\n",
    "# print(mean, stddev)\n",
    "\n",
    "# # 測試是否有通過所有的點\n",
    "# with torch.no_grad():\n",
    "#     # 取得後驗分佈\n",
    "#     posterior = gp.posterior(train_x)\n",
    "    \n",
    "#     # 取得預測平均值 (Mean)\n",
    "#     mean = posterior.mean\n",
    "    \n",
    "#     # 取得預測變異數 (Variance) 或 標準差 (Stddev)\n",
    "#     variance = posterior.variance\n",
    "#     stddev = torch.sqrt(variance)\n",
    "\n",
    "# # 3. 計算誤差 (RMSE)\n",
    "# rmse = torch.sqrt(torch.mean((mean - train_obj)**2))#  \n",
    "# print(f\"訓練集 RMSE: {rmse.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

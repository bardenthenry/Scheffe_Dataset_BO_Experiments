{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/appuser/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "\n",
    "import gpytorch\n",
    "import torch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "from botorch.acquisition import qExpectedImprovement, qLogExpectedImprovement, LogExpectedImprovement\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.test_functions import Ackley\n",
    "from botorch.utils.transforms import unnormalize\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize the 20-dimensional Ackley function\n",
    "fun = Ackley(dim=20, negate=True).to(dtype=dtype, device=device)\n",
    "fun.bounds[0, :].fill_(-5)\n",
    "fun.bounds[1, :].fill_(10)\n",
    "dim = fun.dim\n",
    "lb, ub = fun.bounds\n",
    "\n",
    "batch_size = 4\n",
    "n_init = 2 * dim\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "\n",
    "def eval_objective(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point.\"\"\"\n",
    "    return fun(unnormalize(x, fun.bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintain the TuRBO state\n",
    "@dataclass\n",
    "class TurboState:\n",
    "    \"\"\"Turbo state used to track the recent history of the trust region.\"\"\"\n",
    "    dim: int\n",
    "    batch_size: int\n",
    "    length: float = 0.8\n",
    "    length_min: float = 0.5**7\n",
    "    length_max: float = 1.6\n",
    "    failure_counter: int = 0\n",
    "    failure_tolerance: int = float(\"nan\")  # Note: Post-initialized\n",
    "    success_counter: int = 0\n",
    "    success_tolerance: int = 10  # Note: The original paper uses 3\n",
    "    best_value: float = -float(\"inf\")\n",
    "    restart_triggered: bool = False\n",
    "\n",
    "    def __post_init__(self):\n",
    "        \"\"\"Post-initialize the state of the trust region.\"\"\"\n",
    "        self.failure_tolerance = math.ceil(\n",
    "            max([4.0 / self.batch_size, float(self.dim) / self.batch_size])\n",
    "        )\n",
    "\n",
    "\n",
    "def update_state(state: TurboState, Y_next: torch.Tensor) -> TurboState:\n",
    "    \"\"\"Update the state of the trust region based on the new function values.\"\"\"\n",
    "    if max(Y_next) > state.best_value + 1e-3 * math.fabs(state.best_value):\n",
    "        state.success_counter += 1\n",
    "        state.failure_counter = 0\n",
    "    else:\n",
    "        state.success_counter = 0\n",
    "        state.failure_counter += 1\n",
    "\n",
    "    if state.success_counter == state.success_tolerance:  # Expand trust region\n",
    "        state.length = min(2.0 * state.length, state.length_max)\n",
    "        state.success_counter = 0\n",
    "    elif state.failure_counter == state.failure_tolerance:  # Shrink trust region\n",
    "        state.length /= 2.0\n",
    "        state.failure_counter = 0\n",
    "\n",
    "    state.best_value = max(state.best_value, max(Y_next).item())\n",
    "    if state.length < state.length_min:\n",
    "        state.restart_triggered = True\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TurboState(dim=20, batch_size=4, length=0.8, length_min=0.0078125, length_max=1.6, failure_counter=0, failure_tolerance=5, success_counter=0, success_tolerance=10, best_value=-inf, restart_triggered=False)\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the state\n",
    "state = TurboState(dim=dim, batch_size=batch_size)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate initial points\n",
    "def get_initial_points(dim: int, n_pts: int, seed: int = 0) -> torch.Tensor:\n",
    "    \"\"\"Generate initial points using Sobol sequence.\"\"\"\n",
    "    sobol = SobolEngine(dimension=dim, scramble=True, seed=seed)\n",
    "    return sobol.draw(n=n_pts).to(dtype=dtype, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new batch\n",
    "def generate_batch(\n",
    "    state: TurboState,\n",
    "    model: SingleTaskGP,  # GP model\n",
    "    X: torch.Tensor,  # Evaluated points on the domain [0, 1]^d\n",
    "    Y: torch.Tensor,  # Function values\n",
    "    batch_size: int,\n",
    "    n_candidates: Optional[int] = None,  # Number of candidates for Thompson sampling\n",
    "    num_restarts: int = 10,\n",
    "    raw_samples: int = 512,\n",
    "    acqf: str = \"ts\",  # \"ei\" or \"ts\"\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Generate a new batch of points.\"\"\"\n",
    "    assert acqf in (\"ts\", \"ei\")\n",
    "    assert X.min() >= 0.0\n",
    "    assert X.max() <= 1.0\n",
    "    assert torch.all(torch.isfinite(Y))\n",
    "    if n_candidates is None:\n",
    "        n_candidates = min(5000, max(2000, 200 * X.shape[-1]))\n",
    "\n",
    "    # Scale the TR to be proportional to the lengthscales\n",
    "    x_center = X[Y.argmax(), :].clone()\n",
    "    weights = model.covar_module.base_kernel.lengthscale.squeeze().detach()\n",
    "    weights = weights / weights.mean()\n",
    "    weights = weights / torch.prod(weights.pow(1.0 / len(weights)))\n",
    "    tr_lb = torch.clamp(x_center - weights * state.length / 2.0, 0.0, 1.0)\n",
    "    tr_ub = torch.clamp(x_center + weights * state.length / 2.0, 0.0, 1.0)\n",
    "\n",
    "    if acqf == \"ts\":\n",
    "        dim = X.shape[-1]\n",
    "        sobol = SobolEngine(dim, scramble=True)\n",
    "        pert = sobol.draw(n_candidates).to(dtype=dtype, device=device)\n",
    "        pert = tr_lb + (tr_ub - tr_lb) * pert\n",
    "\n",
    "        # Create a perturbation mask\n",
    "        prob_perturb = min(20.0 / dim, 1.0)\n",
    "        mask = torch.rand(n_candidates, dim, dtype=dtype, device=device) <= prob_perturb\n",
    "        ind = torch.where(mask.sum(dim=1) == 0)[0]\n",
    "        mask[ind, torch.randint(0, dim - 1, size=(len(ind),), device=device)] = 1\n",
    "\n",
    "        # Create candidate points from the perturbations and the mask\n",
    "        X_cand = x_center.expand(n_candidates, dim).clone()\n",
    "        X_cand[mask] = pert[mask]\n",
    "\n",
    "        # Sample on the candidate points\n",
    "        thompson_sampling = MaxPosteriorSampling(model=model, replacement=False)\n",
    "        with torch.no_grad():  # We don't need gradients when using TS\n",
    "            X_next = thompson_sampling(X_cand, num_samples=batch_size)\n",
    "\n",
    "    elif acqf == \"ei\":\n",
    "        ei = LogExpectedImprovement(model, Y.max())\n",
    "        X_next, acq_value = optimize_acqf(\n",
    "            ei,\n",
    "            bounds=torch.stack([tr_lb, tr_ub]),\n",
    "            q=batch_size,\n",
    "            num_restarts=num_restarts,\n",
    "            raw_samples=raw_samples,\n",
    "        )\n",
    "\n",
    "    return X_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization loop\n",
    "X_turbo = get_initial_points(dim, n_init)\n",
    "Y_turbo = torch.tensor(\n",
    "    [eval_objective(x) for x in X_turbo], dtype=dtype, device=device\n",
    ").unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44) Best value: -1.24e+01, TR length: 8.00e-01\n",
      "48) Best value: -1.22e+01, TR length: 8.00e-01\n",
      "52) Best value: -1.14e+01, TR length: 8.00e-01\n",
      "56) Best value: -1.14e+01, TR length: 8.00e-01\n",
      "60) Best value: -1.04e+01, TR length: 8.00e-01\n",
      "64) Best value: -1.04e+01, TR length: 8.00e-01\n",
      "68) Best value: -1.01e+01, TR length: 8.00e-01\n",
      "72) Best value: -7.98e+00, TR length: 8.00e-01\n",
      "76) Best value: -7.98e+00, TR length: 8.00e-01\n",
      "80) Best value: -7.21e+00, TR length: 8.00e-01\n",
      "84) Best value: -7.21e+00, TR length: 8.00e-01\n",
      "88) Best value: -7.21e+00, TR length: 8.00e-01\n",
      "92) Best value: -6.72e+00, TR length: 8.00e-01\n",
      "96) Best value: -6.72e+00, TR length: 8.00e-01\n",
      "100) Best value: -6.72e+00, TR length: 8.00e-01\n",
      "104) Best value: -6.72e+00, TR length: 8.00e-01\n",
      "108) Best value: -6.72e+00, TR length: 8.00e-01\n",
      "112) Best value: -6.72e+00, TR length: 4.00e-01\n",
      "116) Best value: -6.72e+00, TR length: 4.00e-01\n",
      "120) Best value: -6.00e+00, TR length: 4.00e-01\n",
      "124) Best value: -6.00e+00, TR length: 4.00e-01\n",
      "128) Best value: -5.58e+00, TR length: 4.00e-01\n",
      "132) Best value: -5.58e+00, TR length: 4.00e-01\n",
      "136) Best value: -5.58e+00, TR length: 4.00e-01\n",
      "140) Best value: -5.35e+00, TR length: 4.00e-01\n",
      "144) Best value: -5.35e+00, TR length: 4.00e-01\n",
      "148) Best value: -5.35e+00, TR length: 4.00e-01\n",
      "152) Best value: -5.35e+00, TR length: 4.00e-01\n",
      "156) Best value: -5.35e+00, TR length: 4.00e-01\n",
      "160) Best value: -5.35e+00, TR length: 2.00e-01\n",
      "164) Best value: -4.70e+00, TR length: 2.00e-01\n",
      "168) Best value: -4.57e+00, TR length: 2.00e-01\n",
      "172) Best value: -4.53e+00, TR length: 2.00e-01\n",
      "176) Best value: -4.53e+00, TR length: 2.00e-01\n",
      "180) Best value: -4.53e+00, TR length: 2.00e-01\n",
      "184) Best value: -4.14e+00, TR length: 2.00e-01\n",
      "188) Best value: -4.14e+00, TR length: 2.00e-01\n",
      "192) Best value: -3.64e+00, TR length: 2.00e-01\n",
      "196) Best value: -3.64e+00, TR length: 2.00e-01\n",
      "200) Best value: -3.64e+00, TR length: 2.00e-01\n",
      "204) Best value: -3.64e+00, TR length: 2.00e-01\n",
      "208) Best value: -3.64e+00, TR length: 2.00e-01\n",
      "212) Best value: -3.64e+00, TR length: 1.00e-01\n",
      "216) Best value: -3.04e+00, TR length: 1.00e-01\n",
      "220) Best value: -3.04e+00, TR length: 1.00e-01\n",
      "224) Best value: -3.04e+00, TR length: 1.00e-01\n",
      "228) Best value: -3.04e+00, TR length: 1.00e-01\n",
      "232) Best value: -3.04e+00, TR length: 1.00e-01\n",
      "236) Best value: -3.04e+00, TR length: 5.00e-02\n",
      "240) Best value: -2.80e+00, TR length: 5.00e-02\n",
      "244) Best value: -2.74e+00, TR length: 5.00e-02\n",
      "248) Best value: -2.74e+00, TR length: 5.00e-02\n",
      "252) Best value: -2.57e+00, TR length: 5.00e-02\n",
      "256) Best value: -2.28e+00, TR length: 5.00e-02\n",
      "260) Best value: -2.28e+00, TR length: 5.00e-02\n",
      "264) Best value: -2.28e+00, TR length: 5.00e-02\n",
      "268) Best value: -2.28e+00, TR length: 5.00e-02\n",
      "272) Best value: -2.28e+00, TR length: 5.00e-02\n",
      "276) Best value: -2.28e+00, TR length: 2.50e-02\n",
      "280) Best value: -1.96e+00, TR length: 2.50e-02\n",
      "284) Best value: -1.92e+00, TR length: 2.50e-02\n",
      "288) Best value: -1.92e+00, TR length: 2.50e-02\n",
      "292) Best value: -1.92e+00, TR length: 2.50e-02\n",
      "296) Best value: -1.92e+00, TR length: 2.50e-02\n",
      "300) Best value: -1.92e+00, TR length: 2.50e-02\n",
      "304) Best value: -1.92e+00, TR length: 1.25e-02\n",
      "308) Best value: -1.92e+00, TR length: 1.25e-02\n",
      "312) Best value: -1.92e+00, TR length: 1.25e-02\n",
      "316) Best value: -1.92e+00, TR length: 1.25e-02\n",
      "320) Best value: -1.92e+00, TR length: 1.25e-02\n",
      "324) Best value: -1.92e+00, TR length: 6.25e-03\n"
     ]
    }
   ],
   "source": [
    "# Optimization loop\n",
    "X_turbo = get_initial_points(dim, n_init)\n",
    "Y_turbo = torch.tensor(\n",
    "    [eval_objective(x) for x in X_turbo], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "state = TurboState(dim, batch_size=batch_size, best_value=max(Y_turbo).item())\n",
    "\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "while not state.restart_triggered:  # Run until TuRBO converges\n",
    "    # Fit a GP model\n",
    "    train_Y = (Y_turbo - Y_turbo.mean()) / Y_turbo.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    covar_module = ScaleKernel(  # Use the same lengthscale prior as in the TuRBO paper\n",
    "        RBFKernel(ard_num_dims=dim)\n",
    "        # MaternKernel(nu=2.5, ard_num_dims=dim, lengthscale_constraint=Interval(0.005, 4.0))\n",
    "    )\n",
    "    model = SingleTaskGP(X_turbo, train_Y, covar_module=covar_module, likelihood=likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "    # Do the fitting and acquisition function optimization inside the Cholesky context\n",
    "    with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "        # Fit the model\n",
    "        fit_gpytorch_mll(mll)\n",
    "\n",
    "        # Create a batch\n",
    "        X_next = generate_batch(\n",
    "            state=state,\n",
    "            model=model,\n",
    "            X=X_turbo,\n",
    "            Y=train_Y,\n",
    "            batch_size=batch_size,\n",
    "            n_candidates=N_CANDIDATES,\n",
    "            num_restarts=NUM_RESTARTS,\n",
    "            raw_samples=RAW_SAMPLES,\n",
    "            acqf=\"ts\",\n",
    "        )\n",
    "\n",
    "    Y_next = torch.tensor(\n",
    "        [eval_objective(x) for x in X_next], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "\n",
    "    # Update state\n",
    "    state = update_state(state=state, Y_next=Y_next)\n",
    "\n",
    "    # Append data\n",
    "    X_turbo = torch.cat((X_turbo, X_next), dim=0)\n",
    "    Y_turbo = torch.cat((Y_turbo, Y_next), dim=0)\n",
    "\n",
    "    # Print current status\n",
    "    print(f\"{len(X_turbo)}) Best value: {state.best_value:.2e}, TR length: {state.length:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44) Best value: -1.10e+01\n",
      "48) Best value: -1.10e+01\n",
      "52) Best value: -1.10e+01\n",
      "56) Best value: -1.03e+01\n",
      "60) Best value: -1.03e+01\n",
      "64) Best value: -1.03e+01\n",
      "68) Best value: -1.03e+01\n",
      "72) Best value: -1.03e+01\n",
      "76) Best value: -9.63e+00\n",
      "80) Best value: -9.63e+00\n",
      "84) Best value: -9.63e+00\n",
      "88) Best value: -9.63e+00\n",
      "92) Best value: -9.44e+00\n",
      "96) Best value: -9.44e+00\n",
      "100) Best value: -7.97e+00\n",
      "104) Best value: -7.39e+00\n",
      "108) Best value: -7.39e+00\n",
      "112) Best value: -7.39e+00\n",
      "116) Best value: -7.39e+00\n",
      "120) Best value: -6.93e+00\n",
      "124) Best value: -6.93e+00\n",
      "128) Best value: -6.93e+00\n",
      "132) Best value: -6.93e+00\n",
      "136) Best value: -6.93e+00\n",
      "140) Best value: -6.36e+00\n",
      "144) Best value: -5.88e+00\n",
      "148) Best value: -5.88e+00\n",
      "152) Best value: -5.73e+00\n",
      "156) Best value: -5.73e+00\n",
      "160) Best value: -5.09e+00\n",
      "164) Best value: -5.09e+00\n",
      "168) Best value: -5.09e+00\n",
      "172) Best value: -5.09e+00\n",
      "176) Best value: -5.09e+00\n",
      "180) Best value: -5.09e+00\n",
      "184) Best value: -4.61e+00\n",
      "188) Best value: -4.61e+00\n",
      "192) Best value: -4.61e+00\n",
      "196) Best value: -4.61e+00\n",
      "200) Best value: -4.61e+00\n",
      "204) Best value: -4.61e+00\n",
      "208) Best value: -4.61e+00\n",
      "212) Best value: -4.61e+00\n",
      "216) Best value: -4.61e+00\n",
      "220) Best value: -4.61e+00\n",
      "224) Best value: -4.61e+00\n",
      "228) Best value: -4.61e+00\n",
      "232) Best value: -4.61e+00\n",
      "236) Best value: -4.61e+00\n",
      "240) Best value: -4.61e+00\n",
      "244) Best value: -4.61e+00\n",
      "248) Best value: -4.61e+00\n",
      "252) Best value: -3.84e+00\n",
      "256) Best value: -3.84e+00\n",
      "260) Best value: -3.84e+00\n",
      "264) Best value: -3.84e+00\n",
      "268) Best value: -3.84e+00\n",
      "272) Best value: -3.84e+00\n",
      "276) Best value: -3.84e+00\n",
      "280) Best value: -3.84e+00\n",
      "284) Best value: -3.84e+00\n",
      "288) Best value: -3.84e+00\n",
      "292) Best value: -3.84e+00\n",
      "296) Best value: -3.84e+00\n",
      "300) Best value: -3.84e+00\n",
      "304) Best value: -3.84e+00\n",
      "308) Best value: -3.84e+00\n",
      "312) Best value: -3.84e+00\n",
      "316) Best value: -3.84e+00\n",
      "320) Best value: -3.84e+00\n",
      "324) Best value: -3.84e+00\n",
      "328) Best value: -3.84e+00\n",
      "332) Best value: -3.84e+00\n",
      "336) Best value: -3.84e+00\n",
      "340) Best value: -3.04e+00\n",
      "344) Best value: -3.04e+00\n",
      "348) Best value: -3.04e+00\n",
      "352) Best value: -3.04e+00\n"
     ]
    }
   ],
   "source": [
    "# GP-LogEI\n",
    "torch.manual_seed(0)\n",
    "\n",
    "X_logei = get_initial_points(dim, n_init)\n",
    "Y_logei = torch.tensor(\n",
    "    [eval_objective(x) for x in X_logei], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "# Cap the number of evals when running smoke test\n",
    "max_evals = min(len(Y_turbo), n_init + 2 * batch_size) if SMOKE_TEST else len(Y_turbo)\n",
    "while len(Y_logei) < max_evals:\n",
    "    train_Y = (Y_logei - Y_logei.mean()) / Y_logei.std()\n",
    "    likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "    model = SingleTaskGP(X_logei, train_Y, likelihood=likelihood)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    # Create a batch\n",
    "    log_ei = qLogExpectedImprovement(model, train_Y.max())\n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        log_ei,\n",
    "        bounds=torch.stack(\n",
    "            [\n",
    "                torch.zeros(dim, dtype=dtype, device=device),\n",
    "                torch.ones(dim, dtype=dtype, device=device),\n",
    "            ]\n",
    "        ),\n",
    "        q=batch_size,\n",
    "        num_restarts=NUM_RESTARTS,\n",
    "        raw_samples=RAW_SAMPLES,\n",
    "    )\n",
    "    Y_next = torch.tensor(\n",
    "        [eval_objective(x) for x in candidate], dtype=dtype, device=device\n",
    "    ).unsqueeze(-1)\n",
    "\n",
    "    # Append data\n",
    "    X_logei = torch.cat((X_logei, candidate), axis=0)\n",
    "    Y_logei = torch.cat((Y_logei, Y_next), axis=0)\n",
    "\n",
    "    # Print current status\n",
    "    print(f\"{len(X_logei)}) Best value: {Y_logei.max().item():.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44) Best value: -1.07e+01\n",
      "48) Best value: -1.07e+01\n",
      "52) Best value: -1.07e+01\n",
      "56) Best value: -1.07e+01\n",
      "60) Best value: -1.01e+01\n",
      "64) Best value: -9.95e+00\n",
      "68) Best value: -9.95e+00\n",
      "72) Best value: -9.95e+00\n",
      "76) Best value: -9.95e+00\n",
      "80) Best value: -9.43e+00\n",
      "84) Best value: -9.43e+00\n",
      "88) Best value: -9.43e+00\n",
      "92) Best value: -9.43e+00\n",
      "96) Best value: -9.43e+00\n",
      "100) Best value: -9.43e+00\n",
      "104) Best value: -9.43e+00\n",
      "108) Best value: -9.43e+00\n",
      "112) Best value: -9.43e+00\n",
      "116) Best value: -9.43e+00\n",
      "120) Best value: -9.43e+00\n",
      "124) Best value: -9.43e+00\n",
      "128) Best value: -9.43e+00\n",
      "132) Best value: -9.43e+00\n",
      "136) Best value: -9.43e+00\n",
      "140) Best value: -9.43e+00\n",
      "144) Best value: -9.43e+00\n",
      "148) Best value: -9.43e+00\n",
      "152) Best value: -9.43e+00\n",
      "156) Best value: -9.43e+00\n",
      "160) Best value: -9.43e+00\n",
      "164) Best value: -9.43e+00\n",
      "168) Best value: -9.43e+00\n",
      "172) Best value: -9.43e+00\n",
      "176) Best value: -9.43e+00\n",
      "180) Best value: -9.43e+00\n",
      "184) Best value: -9.43e+00\n",
      "188) Best value: -9.43e+00\n",
      "192) Best value: -9.43e+00\n",
      "196) Best value: -9.43e+00\n",
      "200) Best value: -9.43e+00\n",
      "204) Best value: -9.43e+00\n",
      "208) Best value: -9.43e+00\n",
      "212) Best value: -9.43e+00\n",
      "216) Best value: -9.43e+00\n",
      "220) Best value: -9.43e+00\n",
      "224) Best value: -9.43e+00\n",
      "228) Best value: -9.43e+00\n",
      "232) Best value: -9.43e+00\n",
      "236) Best value: -6.13e+00\n",
      "240) Best value: -6.13e+00\n",
      "244) Best value: -6.13e+00\n",
      "248) Best value: -6.13e+00\n",
      "252) Best value: -6.13e+00\n",
      "256) Best value: -6.13e+00\n",
      "260) Best value: -6.13e+00\n",
      "264) Best value: -6.13e+00\n",
      "268) Best value: -6.13e+00\n",
      "272) Best value: -6.13e+00\n",
      "276) Best value: -6.13e+00\n",
      "280) Best value: -6.13e+00\n",
      "284) Best value: -6.13e+00\n",
      "288) Best value: -6.13e+00\n",
      "292) Best value: -6.13e+00\n",
      "296) Best value: -6.13e+00\n",
      "300) Best value: -6.13e+00\n",
      "304) Best value: -6.13e+00\n",
      "308) Best value: -6.13e+00\n",
      "312) Best value: -6.13e+00\n",
      "316) Best value: -6.13e+00\n",
      "320) Best value: -6.13e+00\n",
      "324) Best value: -6.13e+00\n",
      "328) Best value: -6.13e+00\n",
      "332) Best value: -6.13e+00\n",
      "336) Best value: -6.13e+00\n",
      "340) Best value: -6.13e+00\n",
      "344) Best value: -6.13e+00\n",
      "348) Best value: -6.13e+00\n",
      "352) Best value: -6.13e+00\n"
     ]
    }
   ],
   "source": [
    "# GP-EI\n",
    "# torch.manual_seed(0)\n",
    "\n",
    "X_ei = get_initial_points(dim, n_init)\n",
    "Y_ei = torch.tensor([eval_objective(x) for x in X_ei], dtype=dtype, device=device).unsqueeze(-1)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\n",
    "        \"ignore\",\n",
    "        message=\"qExpectedImprovement has known numerical issues\"\n",
    "    )\n",
    "    while len(Y_ei) < len(Y_turbo):\n",
    "        train_Y = (Y_ei - Y_ei.mean()) / Y_ei.std()\n",
    "        likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "        model = SingleTaskGP(X_ei, train_Y, likelihood=likelihood)\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_mll(mll)\n",
    "\n",
    "        # Create a batch\n",
    "        ei = qExpectedImprovement(model, train_Y.max())\n",
    "        candidate, acq_value = optimize_acqf(\n",
    "            ei,\n",
    "            bounds=torch.stack(\n",
    "                [\n",
    "                    torch.zeros(dim, dtype=dtype, device=device),\n",
    "                    torch.ones(dim, dtype=dtype, device=device),\n",
    "                ]\n",
    "            ),\n",
    "            q=batch_size,\n",
    "            num_restarts=NUM_RESTARTS,\n",
    "            raw_samples=RAW_SAMPLES,\n",
    "        )\n",
    "        Y_next = torch.tensor(\n",
    "            [eval_objective(x) for x in candidate], dtype=dtype, device=device\n",
    "        ).unsqueeze(-1)\n",
    "\n",
    "        # Append data\n",
    "        X_ei = torch.cat((X_ei, candidate), axis=0)\n",
    "        Y_ei = torch.cat((Y_ei, Y_next), axis=0)\n",
    "\n",
    "        # Print current status\n",
    "        print(f\"{len(X_ei)}) Best value: {Y_ei.max().item():.2e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
